import cv2
import os
import math
import argparse
import numpy as np
import mediapipe as mp
from deepface import DeepFace
from scipy.spatial.distance import cosine

def cosine_distance(v1, v2):
    return cosine(v1, v2)

def track_faces_mediapipe(video_path, output_dir="output_faces", max_frames=300, threshold=0.5):
    print(f"[ğŸš€ ì‹œì‘] '{video_path}' ì—ì„œ MediaPipe + ArcFace ì–¼êµ´ ì¶”ì ")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("[âŒ ì˜¤ë¥˜] ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨")
        return

    mp_face = mp.solutions.face_detection
    face_detection = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6)

    os.makedirs(output_dir, exist_ok=True)

    person_db = {}
    person_counter = 0
    frame_count = 0

    while cap.isOpened() and frame_count < max_frames:
        ret, frame = cap.read()
        if not ret:
            break
        frame_count += 1
        print(f"[ğŸ“· í”„ë ˆì„ {frame_count}] ì²˜ë¦¬ ì¤‘...")

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_detection.process(rgb)

        if not results.detections:
            print("  â””â”€ ì–¼êµ´ ì—†ìŒ")
            continue

        for i, detection in enumerate(results.detections):
            bbox = detection.location_data.relative_bounding_box
            h, w, _ = frame.shape
            x = int(bbox.xmin * w)
            y = int(bbox.ymin * h)
            w_box = int(bbox.width * w)
            h_box = int(bbox.height * h)

            x, y = max(x, 0), max(y, 0)
            face_img = frame[y:y+h_box, x:x+w_box]

            if w_box < 60 or h_box < 60:
                print("    â””â”€ ë„ˆë¬´ ì‘ì€ ì–¼êµ´, ìŠ¤í‚µ")
                continue

            try:
                embedding = DeepFace.represent(face_img, model_name="ArcFace", enforce_detection=False)[0]['embedding']
            except Exception as e:
                print(f"    [!] ì–¼êµ´ ì•„ë‹˜ or ì¸ì‹ ì‹¤íŒ¨: {e}")
                continue

            matched_id = None
            min_dist = 1.0

            for pid, data in person_db.items():
                avg_emb = np.mean(data['embeddings'], axis=0)
                dist = cosine_distance(embedding, avg_emb)
                if dist < threshold and dist < min_dist:
                    matched_id = pid
                    min_dist = dist

            if matched_id:
                person_id = matched_id
                print(f"    âœ… ê¸°ì¡´ ì¸ë¬¼ ì¸ì‹ë¨: {person_id} (ê±°ë¦¬={min_dist:.4f})")
                person_db[person_id]['embeddings'].append(embedding)
                person_db[person_id]['last_seen'] = frame_count
            else:
                person_counter += 1
                person_id = f"P{person_counter}"
                print(f"    â• ìƒˆë¡œìš´ ì¸ë¬¼ ë“±ë¡: {person_id}")
                person_db[person_id] = {
                    'embeddings': [embedding],
                    'last_seen': frame_count
                }

            # ì €ì¥
            person_folder = os.path.join(output_dir, person_id)
            os.makedirs(person_folder, exist_ok=True)
            save_path = os.path.join(person_folder, f"frame{frame_count}.jpg")
            cv2.imwrite(save_path, face_img)

            # ì‹œê°í™”
            cv2.rectangle(frame, (x, y), (x+w_box, y+h_box), (0,255,0), 2)
            cv2.putText(frame, person_id, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)

        cv2.imshow("Tracking", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("[ğŸ›‘ ì‚¬ìš©ì ì¢…ë£Œ]")
            break

    cap.release()
    cv2.destroyAllWindows()
    print("[âœ… ì™„ë£Œ] ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ")

# âœ… main
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="MediaPipe + ArcFace ì–¼êµ´ íŠ¸ë˜í‚¹")
    parser.add_argument("video_path", type=str, help="ë¹„ë””ì˜¤ ê²½ë¡œ")
    parser.add_argument("--output_dir", type=str, default="output_faces")
    parser.add_argument("--max_frames", type=int, default=300)
    parser.add_argument("--threshold", type=float, default=0.55)

    args = parser.parse_args()
    track_faces_mediapipe(
        args.video_path,
        args.output_dir,
        args.max_frames,
        args.threshold
    )
