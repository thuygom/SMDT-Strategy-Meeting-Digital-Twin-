import pymysql
from collections import Counter
from chat_execute import ask_function_call
from chat_execute import analyze_comments_with_gpt
from chat_execute import analyze_statistics_with_gpt
from chat_execute import analyze_comparison_with_gpt
from chat_execute import analyze_contents_with_gpt
from rich import print as rprint
from collections import defaultdict
import random

# âœ… DB ì—°ê²°
def connect_to_db():
    return pymysql.connect(
        host='localhost',
        user='root',
        password='Bandalgom!0927',
        database='my_new_db',
        charset='utf8mb4',
        cursorclass=pymysql.cursors.DictCursor
    )

# âœ… ìœ íŠœë¸Œ ëŒ“ê¸€+ë©”íƒ€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def get_youtube_comment_data(connection, influencer_name=None, date=None, video_url=None):
    """
    ìœ íŠœë¸Œ ëŒ“ê¸€ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì¡°ê±´ì— ë”°ë¼ ì¡°íšŒ (topic_categories í¬í•¨)
    :param connection: DB ì—°ê²° ê°ì²´
    :param influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
    :param date: ì˜ìƒ ë‚ ì§œ
    :param video_url: ì˜ìƒ URL
    :return: ì¡°íšŒëœ ëŒ“ê¸€ ë° ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    query = """
        SELECT 
            yc.video_url,
            y.title,
            yc.comment,
            yc.emotion,
            yc.topic,
            y.topic_categories,  -- âœ… ì¶”ê°€ëœ ì»¬ëŸ¼
            yc.cluster,
            yc.score,
            yc.fss as SCOPE_score,
            y.view_count,
            y.like_count,
            y.comment_count,
            y.subscriber_count,
            y.date
        FROM youtube_comment yc
        JOIN youtube y ON yc.video_url = y.video_url
    """
    conditions = []
    params = []

    if video_url:
        conditions.append("y.video_url = %s")
        params.append(video_url)
    else:
        if influencer_name:
            conditions.append("y.influencer_name = %s")
            params.append(influencer_name)
        if date:
            conditions.append("DATE(y.date) = %s")
            params.append(date)

    if conditions:
        query += " WHERE " + " AND ".join(conditions)

    with connection.cursor() as cursor:
        cursor.execute(query, tuple(params))
        return cursor.fetchall()

def comments_sample(connection, influencer_name=None, date=None, limit=10,
                    emotion=None, topic=None, cluster=None, video_url=None):
    """
    ëŒ“ê¸€ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ê¸°ë³¸ 10ê°œ)
    """
    data = get_youtube_comment_data(connection, influencer_name, date)
    if not data:
        return "âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    # âœ… ê°ì • ë§¤í•‘
    emotion_map = {
        "positive": ["í–‰ë³µ"],
        "negative": ["ë¶„ë…¸", "í˜ì˜¤", "ìŠ¬í””"]
    }

    # âœ… í•„í„°ë§
    filtered = []
    for row in data:
        if video_url and row["video_url"] != video_url:
            continue
        if emotion:
            if emotion in emotion_map:
                if row["emotion"] not in emotion_map[emotion]:
                    continue
            elif row["emotion"] != emotion:
                continue
        if topic and row["topic"] != topic:
            continue
        if cluster and row["cluster"] != cluster:
            continue
        filtered.append(row)

    if not filtered:
        return "âš ï¸ ì¡°ê±´ì— ë§ëŠ” ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤."

    # âœ… ë¬´ì‘ìœ„ ìƒ˜í”Œë§
    sampled = random.sample(filtered, min(limit, len(filtered)))

    # âœ… ê²°ê³¼ í¬ë§·
    target_label = f"{influencer_name or 'ì „ì²´'} - {date or 'ì „ì²´'}"
    if video_url:
        target_label += f" - ì˜ìƒ: {video_url}"
    if emotion in ["positive", "negative"]:
        target_label += f" - ê°ì •: {emotion}"

    lines = [f"\nğŸ“‹ [{target_label}] í•„í„°ë§ëœ ëŒ“ê¸€ ìƒ˜í”Œ {len(sampled)}ê°œ:"]
    for i, row in enumerate(sampled, 1):
        lines.append(
            f"{i}. ({row['date']}) [{row['video_url']}] {row['comment']}\n"
            f"   â–¶ ê°ì •: {row['emotion']} / ì£¼ì œ: {row['topic']} / í´ëŸ¬ìŠ¤í„°: {row['cluster']} / "
            f"ì ìˆ˜: {row['score']} / SCOPE_score: {row['SCOPE_score']}"
        )
    return "\n".join(lines)

# âœ… í‰ê·  ê³„ì‚°
def calculate_average_stats(data):
    keys = ['SCOPE_score', 'view_count', 'like_count', 'comment_count', 'subscriber_count']
    avg_stats = {}
    for key in keys:
        values = [row[key] for row in data if row.get(key) is not None]
        avg_stats[f"avg_{key}"] = sum(values) / len(values) if values else 0
    return avg_stats

# âœ… ë¶„í¬ ê³„ì‚°
def calculate_distribution(data, key):
    counter = Counter([row[key] for row in data if row.get(key)])
    total = sum(counter.values())
    return {k: round((v / total) * 100, 2) for k, v in counter.items()} if total > 0 else {}

def format_stat_dict(title, stat_dict):
    """
    í†µê³„ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
    :param title: ì¶œë ¥ ì œëª©
    :param stat_dict: {í•­ëª©: ê°’} í˜•íƒœì˜ í‰ê·  í†µê³„ ë”•ì…”ë„ˆë¦¬
    :return: í¬ë§·ëœ ë¬¸ìì—´
    """
    lines = [f"\n[{title}]"]
    for key, value in stat_dict.items():
        lines.append(f"{key}: {value:.2f}")
    return "\n".join(lines)

def format_distribution(title, dist_dict):
    """
    ë¶„í¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
    :param title: ì¶œë ¥ ì œëª©
    :param dist_dict: {ì¹´í…Œê³ ë¦¬: í¼ì„¼íŠ¸} í˜•íƒœì˜ ë¶„í¬ ë”•ì…”ë„ˆë¦¬
    :return: í¬ë§·ëœ ë¬¸ìì—´
    """
    lines = [f"\n[{title}]"]
    for key, pct in dist_dict.items():
        lines.append(f"- {key}: {pct}%")
    return "\n".join(lines)

# âœ… ë‚ ì§œ ì„ íƒ ìœ ë„
def select_available_dates(connection, influencer_name):
    """
    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ ìœ íš¨í•œ ë‚ ì§œ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ìµœê³ /ìµœì € SCOPE_score ë‚ ì§œ ê°•ì¡° í¬í•¨)
    :param connection: DB ì—°ê²° ê°ì²´
    :param influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
    :return: ë‚ ì§œ ëª©ë¡ ë¬¸ìì—´
    """
    # ìœ íš¨ ë‚ ì§œ ì¡°íšŒ
    query = """
        SELECT DISTINCT y.date 
        FROM youtube y 
        WHERE y.influencer_name = %s 
        ORDER BY y.date
    """
    with connection.cursor() as cursor:
        cursor.execute(query, (influencer_name,))
        rows = cursor.fetchall()
        dates = [row['date'] for row in rows]

    if not dates:
        return f"âš ï¸ [{influencer_name}]ì˜ ìœ íš¨í•œ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤."

    # ìµœê³  ë° ìµœì € ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
    best_date = select_best_stats_date(connection, influencer_name)
    worst_date = select_worst_stats_date(connection, influencer_name)

    result = [f"ğŸ“… [{influencer_name}]ì˜ ìœ íš¨í•œ ë‚ ì§œ ëª©ë¡:"]
    for i, date in enumerate(dates):
        label = ""
        if date == best_date:
            label += "ğŸŒŸ ìµœê³  ì„±ê³¼ì¼"
        if date == worst_date:
            if label: label += " / "
            label += "ğŸ“‰ ìµœì € ì„±ê³¼ì¼"
        result.append(f"{i + 1}. {date}" + (f"  â† {label}" if label else ""))
    
    return "\n".join(result)

def select_available_influencers(connection):
    """
    ìœ íš¨í•œ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜
    :param connection: DB ì—°ê²° ê°ì²´
    :return: ì¸í”Œë£¨ì–¸ì„œ ëª©ë¡ ë¬¸ìì—´
    """
    query = """
        SELECT DISTINCT influencer_name 
        FROM youtube 
        ORDER BY influencer_name
    """
    with connection.cursor() as cursor:
        cursor.execute(query)
        rows = cursor.fetchall()
        names = [row['influencer_name'] for row in rows]

    if not names:
        return "âš ï¸ ë“±ë¡ëœ ì¸í”Œë£¨ì–¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."

    result = ["ğŸ§‘â€ğŸ’» ìœ íš¨í•œ ì¸í”Œë£¨ì–¸ì„œ ëª©ë¡:"]
    for i, name in enumerate(names):
        result.append(f"{i + 1}. {name}")

    return "\n".join(result)

def select_available_video_urls(connection, influencer_name):
    """
    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ ìœ íš¨í•œ ì˜ìƒ ì œëª© ë° YouTube ID ëª©ë¡ì„ ë‚ ì§œë³„ë¡œ ì •ë¦¬í•´ ë¬¸ìì—´ë¡œ ë°˜í™˜
    :param connection: DB ì—°ê²° ê°ì²´
    :param influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
    :return: ì˜ìƒ ì œëª© ëª©ë¡ ë¬¸ìì—´
    """
    query = """
        SELECT date, title, video_url
        FROM youtube
        WHERE influencer_name = %s
        ORDER BY date
    """
    with connection.cursor() as cursor:
        cursor.execute(query, (influencer_name,))
        rows = cursor.fetchall()

    if not rows:
        return f"âš ï¸ [{influencer_name}]ì˜ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."

    result = [f"ğŸ¬ [{influencer_name}]ì˜ ì˜ìƒ ëª©ë¡ (ì œëª© + YouTube ID):"]
    for i, row in enumerate(rows):
        date = row['date']
        title = row['title']
        url = row['video_url']
        video_id = url.split("v=")[-1].split("&")[0] if "v=" in url else "â“ID ì—†ìŒ"
        result.append(f"{i + 1}. ({date}) ã€{title}ã€ (ğŸï¸ ID: {video_id})")

    return "\n".join(result)

# âœ… ìµœê³  SCOPE_score ë‚ ì§œ êµ¬í•˜ê¸°
def select_best_stats_date(connection, influencer_name):
    query = """
        SELECT y.date
        FROM youtube_comment yc
        JOIN youtube y ON yc.video_url = y.video_url
        WHERE y.influencer_name = %s
        GROUP BY y.date
        ORDER BY AVG(fss) DESC
        LIMIT 1
    """
    with connection.cursor() as cursor:
        cursor.execute(query, (influencer_name,))
        row = cursor.fetchone()
        return row['date'] if row else None

# âœ… ìµœì € SCOPE_score ë‚ ì§œ êµ¬í•˜ê¸°
def select_worst_stats_date(connection, influencer_name):
    query = """
        SELECT y.date
        FROM youtube_comment yc
        JOIN youtube y ON yc.video_url = y.video_url
        WHERE y.influencer_name = %s
        GROUP BY y.date
        ORDER BY AVG(fss) ASC
        LIMIT 1
    """
    with connection.cursor() as cursor:
        cursor.execute(query, (influencer_name,))
        row = cursor.fetchone()
        return row['date'] if row else None

def compare_two_stats(original_stats, compare_stats):
    """
    ë‘ ê°œì˜ í†µê³„ dictë¥¼ ë¹„êµí•˜ì—¬ í•­ëª©ë³„ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ì ˆëŒ“ê°’ + í¼ì„¼íŠ¸ ì°¨ì´)
    """
    result = [f"\nğŸ“Š í•­ëª©ë³„ ì°¨ì´ (ê¸°ì¤€ - ë¹„êµëŒ€ìƒ)"]
    for key in original_stats:
        if key.startswith("avg_") and key in compare_stats:
            orig = original_stats[key]
            comp = compare_stats[key]
            diff = orig - comp

            # í¼ì„¼íŠ¸ ì°¨ì´ ê³„ì‚° (compê°€ 0ì´ë©´ 'N/A')
            if comp == 0:
                pct = "N/A"
            else:
                pct = f"{(diff / comp) * 100:+.2f}%"

            result.append(f"{key}: {orig:.2f} - {comp:.2f} = {diff:+.2f} ({pct})")
    return "\n".join(result)

def compare_distributions(dist1, dist2):
    """
    ë‘ ë¶„í¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¹„êµí•˜ì—¬ ê³µí†µëœ ë¼ë²¨ì— ëŒ€í•´ í¼ì„¼íŠ¸ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    lines = [f"\nğŸ“Š ê³µí†µ ì¹´í…Œê³ ë¦¬ë³„ í¼ì„¼íŠ¸ ì°¨ì´ (ê¸°ì¤€ - ë¹„êµëŒ€ìƒ)"]

    common_keys = set(dist1.keys()).intersection(dist2.keys())
    if not common_keys:
        lines.append("âš ï¸ ê³µí†µëœ ë¼ë²¨ì´ ì—†ì–´ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return "\n".join(lines)

    for key in sorted(common_keys):
        try:
            val1 = dist1[key]
            val2 = dist2[key]
            diff = val1 - val2
            lines.append(f"{key}: {val1:.2f}% - {val2:.2f}% = {diff:+.2f}pp")
        except Exception as e:
            lines.append(f"{key}: ë¹„êµ ì‹¤íŒ¨ ({e})")

    return "\n".join(lines)

#ì „ì²´ ì¸í”Œë£¨ì–¸ì„œ í‰ê·  í†µê³„ ë³´ì—¬ì¤˜
def get_global_statistics(connection):
    """
    ì „ì²´ ì¸í”Œë£¨ì–¸ì„œì˜ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    all_data = get_youtube_comment_data(connection)
    lines = [
        format_stat_dict("ì „ì²´ ì¸í”Œë£¨ì–¸ì„œ í‰ê·  í†µê³„", calculate_average_stats(all_data)),
        format_distribution("ì „ì²´ ê°ì • ë¶„í¬", calculate_distribution(all_data, "emotion")),
        format_distribution("ì „ì²´ ì£¼ì œ ë¶„í¬", calculate_distribution(all_data, "topic")),
        format_distribution("ì „ì²´ í´ëŸ¬ìŠ¤í„° ë¶„í¬", calculate_distribution(all_data, "cluster")),
    ]
    return "\n".join(lines)

#íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œ í‰ê·  í†µê³„ ë³´ì—¬ì¤˜
def get_influencer_statistics(connection, influencer_name):
    """
    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    inf_data = get_youtube_comment_data(connection, influencer_name)
    lines = [
        format_stat_dict(f"{influencer_name} í‰ê·  í†µê³„", calculate_average_stats(inf_data)),
        format_distribution(f"{influencer_name} ê°ì • ë¶„í¬", calculate_distribution(inf_data, "emotion")),
        format_distribution(f"{influencer_name} ì£¼ì œ ë¶„í¬", calculate_distribution(inf_data, "topic")),
        format_distribution(f"{influencer_name} í´ëŸ¬ìŠ¤í„° ë¶„í¬", calculate_distribution(inf_data, "cluster")),
    ]
    return "\n".join(lines)

#íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ íŠ¹ì • ë‚ ì§œ í†µê³„ ë³´ì—¬ì¤˜
def get_statistics_by_date(connection, influencer_name, selected_date):
    """
    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    date_data = get_youtube_comment_data(connection, influencer_name, selected_date)
    lines = [
        format_stat_dict(f"{influencer_name}ì˜ {selected_date} í‰ê·  í†µê³„", calculate_average_stats(date_data)),
        format_distribution(f"{influencer_name}ì˜ {selected_date} ê°ì • ë¶„í¬", calculate_distribution(date_data, "emotion")),
        format_distribution(f"{influencer_name}ì˜ {selected_date} ì£¼ì œ ë¶„í¬", calculate_distribution(date_data, "topic")),
        format_distribution(f"{influencer_name}ì˜ {selected_date} í´ëŸ¬ìŠ¤í„° ë¶„í¬", calculate_distribution(date_data, "cluster")),
    ]
    return "\n".join(lines)

def get_statistics_by_video_url(connection, video_url):
    """
    íŠ¹ì • video_url(í•´ì‹œ or ì „ì²´ URL)ì— ëŒ€í•œ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    # URL í•´ì‹œê°’ë§Œ ë“¤ì–´ì™”ë‹¤ë©´ ì „ì²´ URLë¡œ ë³€í™˜
    if not video_url.startswith("http"):
        video_url = f"https://www.youtube.com/watch?v={video_url}"

    video_data = get_youtube_comment_data(connection, video_url=video_url)

    if not video_data:
        return f"âš ï¸ í•´ë‹¹ ì˜ìƒ({video_url})ì— ëŒ€í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

    title = video_data[0]['title']
    date = video_data[0]['date']

    lines = [
        format_stat_dict(f"ğŸ¥ ã€{title}ã€ ({date}) í‰ê·  í†µê³„", calculate_average_stats(video_data)),
        format_distribution(f"ğŸ­ ã€{title}ã€ ê°ì • ë¶„í¬", calculate_distribution(video_data, "emotion")),
        format_distribution(f"ğŸ§  ã€{title}ã€ ì£¼ì œ ë¶„í¬", calculate_distribution(video_data, "topic")),
        format_distribution(f"ğŸ‘¥ ã€{title}ã€ í´ëŸ¬ìŠ¤í„° ë¶„í¬", calculate_distribution(video_data, "cluster")),
    ]
    return "\n".join(lines)

def compare_two_influencers_dates(connection, influencer1,influencer2=None, date1=None, date2=None):
    """
    ë‘ ì¸í”Œë£¨ì–¸ì„œì˜ íŠ¹ì • ë‚ ì§œ ë˜ëŠ” ì „ì²´ ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ í‰ê·  í†µê³„ ë° ë¶„í¬ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
    :param connection: DB ì—°ê²° ê°ì²´
    :param influencer1: ì²« ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
    :param date1: ì²« ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ë‚ ì§œ (Noneì´ë©´ ì „ì²´)
    :param influencer2: ë‘ ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ (Noneì´ë©´ influencer1ê³¼ ë™ì¼í•˜ê²Œ ë¹„êµ)
    :param date2: ë‘ ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ë‚ ì§œ (Noneì´ë©´ ì „ì²´)
    :return: ë¹„êµ ê²°ê³¼ ë¬¸ìì—´
    """
    if not influencer2:
        influencer2 = influencer1  # ê°™ì€ ì‚¬ëŒ ë¹„êµ

    result_lines = []

    # ğŸ”¹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data1 = get_youtube_comment_data(connection, influencer1, date1)
    data2 = get_youtube_comment_data(connection, influencer2, date2)

    # ğŸ”¹ íƒ€ì´í‹€ ì„¤ì •
    title = f"{influencer1}({date1 or 'ì „ì²´'}) vs {influencer2}({date2 or 'ì „ì²´'}) í‰ê·  í†µê³„ ë¹„êµ"

    # ğŸ“Š í‰ê·  í†µê³„ ë¹„êµ
    avg_stats_1 = calculate_average_stats(data1)
    avg_stats_2 = calculate_average_stats(data2)
    result_lines.append(compare_two_stats(avg_stats_1, avg_stats_2))

    # ğŸ“Š ë¶„í¬ ë¹„êµ (ê°ì •, ì£¼ì œ, í´ëŸ¬ìŠ¤í„°)
    for category in ["emotion", "topic", "cluster"]:
        dist_1 = calculate_distribution(data1, category)
        dist_2 = calculate_distribution(data2, category)
        result_lines.append(
            compare_distributions(
                dist_1, dist_2
                )
        )

    return "\n".join(result_lines)

def analyze_overall_fss_by_category(connection, influencer_name, top_n=3, min_count=5):
    """
    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ ì „ì²´ ì½˜í…ì¸ ì— ëŒ€í•´ topic_categoriesë³„ í‰ê·  FSS ë¶„ì„
    (Wikipedia URLì€ í•­ëª© ì´ë¦„ë§Œ ì¶”ì¶œí•´ í‘œì‹œ)
    """
    from collections import defaultdict

    video_data = get_youtube_comment_data(connection, influencer_name=influencer_name)
    
    if not video_data:
        return f"âš ï¸ [{influencer_name}]ì— ëŒ€í•œ ëŒ“ê¸€ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

    category_scores = defaultdict(list)

    for row in video_data:
        raw = row.get('topic_categories') or "ë¯¸ë¶„ë¥˜"
        score = row.get('SCOPE_score')
        if score is not None:
            category_scores[raw].append(score)

    filtered = {
        cat: scores for cat, scores in category_scores.items()
        if len(scores) >= min_count
    }

    if not filtered:
        return f"âš ï¸ ë¶„ì„ ê°€ëŠ¥í•œ ì£¼ì œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. (ëŒ“ê¸€ ìˆ˜ ë¶€ì¡±)"

    category_avg = {
        cat: sum(scores) / len(scores)
        for cat, scores in filtered.items()
    }

    sorted_avg = sorted(category_avg.items(), key=lambda x: x[1], reverse=True)
    top = sorted_avg[:top_n]
    bottom = sorted_avg[-top_n:]

    def simplify_category(cat):
        if cat == "ë¯¸ë¶„ë¥˜":
            return cat
        # ì—¬ëŸ¬ ê°œì¼ ê²½ìš° ë¶„ë¦¬ í›„ ê°ê° ì²˜ë¦¬
        parts = [part.strip() for part in cat.split(',')]
        simplified = []
        for p in parts:
            if "en.wikipedia.org/wiki/" in p:
                simplified.append(p.split("en.wikipedia.org/wiki/")[-1])
            else:
                simplified.append(p)
        return ", ".join(simplified)

    lines = [f"\nğŸ“ˆ [{influencer_name}]ë‹˜ì˜ ì½˜í…ì¸  ë°©í–¥ì„± ì œì•ˆ (SCOPE_score ê¸°ë°˜):"]

    lines.append("\nâœ… ì•ìœ¼ë¡œ ë” í™œìš©í•´ë³¼ë§Œí•œ ì£¼ì œ ì¹´í…Œê³ ë¦¬:")
    for cat, avg in top:
        lines.append(f"  - {simplify_category(cat)}: í‰ê·  SCOPE_score {avg:.2f}")

    lines.append("\nâš ï¸ ë°˜ì‘ì´ ë‚®ì•˜ë˜ ì£¼ì œ ì¹´í…Œê³ ë¦¬:")
    for cat, avg in bottom:
        lines.append(f"  - {simplify_category(cat)}: í‰ê·  SCOPE_score {avg:.2f}")

    return "\n".join(lines)

def ask_for_additional_analysis():
    user_input = input("\nğŸ§  ì¶”ê°€ GPT ë¶„ì„ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    return user_input == "y"

if __name__ == "__main__":
    connection = connect_to_db()

    try:
        rprint("[bold green]ğŸ§  SCOPE ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! 'exit' ì…ë ¥ ì‹œ ì¢…ë£Œë©ë‹ˆë‹¤.[/bold green]")

        while True:
            user_query = input("\nğŸ‘¤ ì‚¬ìš©ì: ")

            if user_query.lower() in ["exit", "quit"]:
                rprint("[bold red]ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.[/bold red]")
                break

            elif user_query.strip().lower() == "cls":
                rprint("[bold yellow]âœ… ì»¨í…ìŠ¤íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”.[/bold yellow]")
                continue

            try:
                # í•¨ìˆ˜ í˜¸ì¶œ ì¶”ë¡ 
                call_string = ask_function_call(user_query)
                rprint(f"ğŸ“Œ í˜¸ì¶œí•  í•¨ìˆ˜: [cyan]{call_string}[/cyan]")

                # í•¨ìˆ˜ ì‹¤í–‰ (ë¬¸ìì—´ ë”°ì˜´í‘œ ì œê±° í›„ eval)
                true_call_string = call_string.strip('"')
                
                if true_call_string.startswith(("select_")):
                    result = eval(true_call_string)
                    rprint(f"ğŸ“Š ê²°ê³¼:\n{result}")

                elif true_call_string.startswith(("analyze_")):
                    result = eval(true_call_string)
                    rprint(f"ğŸ“Š ê²°ê³¼:\n{result}")

                    if ask_for_additional_analysis():
                        rprint("\n[bold magenta]GPT ë¶„ì„ ì¤‘...[/bold magenta]")
                        summary = analyze_contents_with_gpt(result)
                        rprint(f"\nğŸ§¾ GPT ë¶„ì„ ê²°ê³¼:\n{summary}")

                elif true_call_string.startswith(("get_")):
                    result = eval(true_call_string)
                    rprint(f"ğŸ“Š ê²°ê³¼:\n{result}")

                    if ask_for_additional_analysis():
                        rprint("\n[bold magenta]GPT ë¶„ì„ ì¤‘...[/bold magenta]")
                        summary = analyze_statistics_with_gpt(result)
                        rprint(f"\nğŸ§¾ GPT ë¶„ì„ ê²°ê³¼:\n{summary}")

                elif true_call_string.startswith(("compare_")):
                    result = eval(true_call_string)
                    rprint(f"ğŸ“Š ê²°ê³¼:\n{result}")

                    if ask_for_additional_analysis():
                        rprint("\n[bold magenta]GPT ë¶„ì„ ì¤‘...[/bold magenta]")
                        summary = analyze_comparison_with_gpt(user_query + result)
                        rprint(f"\nğŸ§¾ GPT ë¶„ì„ ê²°ê³¼:\n{summary}")

                elif true_call_string.startswith("comments_"):
                    comment_text = eval(true_call_string)
                    rprint(f"ğŸ“Š ê²°ê³¼:\n{comment_text}")

                    if ask_for_additional_analysis():
                        rprint("\n[bold magenta]GPT ë¶„ì„ ì¤‘...[/bold magenta]")
                        summary = analyze_comments_with_gpt(comment_text)
                        rprint(f"\nğŸ§¾ GPT ë¶„ì„ ê²°ê³¼:\n{summary}")

                else:
                    rprint(f"[dim]{true_call_string}[/dim]")

            except Exception as e:
                rprint(f"[bold red]âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}[/bold red]")

    finally:
        connection.close()