{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import copy\n",
    "\n",
    "class NASController:\n",
    "    def __init__(self, prior_path, mutation_rate=0.1, alpha=0.6, weight=0.8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prior_path: JSON file containing list of subnet dicts with \"mask\" keys\n",
    "            mutation_rate: probability of bit flip per path\n",
    "            alpha: EMA smoothing factor\n",
    "            weight: trade-off between acc and flops (e.g., 0.8 means 80% acc, 20% flops)\n",
    "        \"\"\"\n",
    "        with open(prior_path, 'r') as f:\n",
    "            self.subnets = json.load(f)\n",
    "\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.alpha = alpha\n",
    "        self.weight = weight\n",
    "\n",
    "        self.rewards = {tuple(s[\"mask\"]): 0.0 for s in self.subnets}\n",
    "        self.trained_masks = set()\n",
    "        self.flops_cache = {}  # Optional: mask → flops\n",
    "\n",
    "    def sample_subnets(self, top_k=10):\n",
    "        \"\"\"\n",
    "        Select top-k subnetworks based on reward and apply mutation\n",
    "        \"\"\"\n",
    "        sorted_subnets = sorted(\n",
    "            self.subnets,\n",
    "            key=lambda x: self.rewards.get(tuple(x[\"mask\"]), 0),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        top_subnets = []\n",
    "        for s in sorted_subnets:\n",
    "            mask_tuple = tuple(s[\"mask\"])\n",
    "            if mask_tuple not in self.trained_masks:\n",
    "                top_subnets.append(s[\"mask\"])\n",
    "            if len(top_subnets) >= top_k:\n",
    "                break\n",
    "\n",
    "        # Mutation\n",
    "        mutated = []\n",
    "        for mask in top_subnets:\n",
    "            new_mask = copy.deepcopy(mask)\n",
    "            for i in range(len(mask)):\n",
    "                if random.random() < self.mutation_rate:\n",
    "                    new_mask[i] = 1 - new_mask[i]  # flip 0↔1\n",
    "            mutated.append(new_mask)\n",
    "\n",
    "        return mutated\n",
    "\n",
    "    def update_rewards(self, subnet_masks, acc_score, flops=None):\n",
    "        \"\"\"\n",
    "        Update EMA reward for each subnet\n",
    "        \"\"\"\n",
    "        for mask in subnet_masks:\n",
    "            key = tuple(mask)\n",
    "\n",
    "            # multi-objective reward: weighted acc/flops\n",
    "            reward = acc_score\n",
    "            if flops is not None:\n",
    "                reward = self.weight * acc_score - (1 - self.weight) * flops\n",
    "\n",
    "            # EMA update\n",
    "            old_reward = self.rewards.get(key, 0.0)\n",
    "            new_reward = self.alpha * reward + (1 - self.alpha) * old_reward\n",
    "            self.rewards[key] = new_reward\n",
    "\n",
    "            self.trained_masks.add(key)\n",
    "\n",
    "    def save_rewards(self, path=\"nas_reward_log.json\"):\n",
    "        \"\"\"\n",
    "        Save rewards to JSON file\n",
    "        \"\"\"\n",
    "        log = [{\"mask\": list(k), \"reward\": v} for k, v in self.rewards.items()]\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "\n",
    "    def cache_flops(self, mask, flops):\n",
    "        \"\"\"\n",
    "        Optional: Store flops for each mask\n",
    "        \"\"\"\n",
    "        self.flops_cache[tuple(mask)] = flops\n",
    "\n",
    "    def get_cached_flops(self, mask):\n",
    "        return self.flops_cache.get(tuple(mask), None)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
