{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af45af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "\n",
    "# â–¶ Hugging Face ì•¡ì„¸ìŠ¤ í† í°\n",
    "\n",
    "# â–¶ ë””ë ‰í† ë¦¬ ê³ ì •\n",
    "AUDIO_DIR = \"D:/youtube_downloads\"\n",
    "\n",
    "# â–¶ pyannote pipeline ë¡œë“œ\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=ACCESS_TOKEN)\n",
    "pipeline.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# â–¶ ì „ì²´ ë””ë ‰í† ë¦¬ ì²˜ë¦¬\n",
    "def process_directory(directory_path):\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith(\".wav\"):\n",
    "            wav_path = os.path.join(directory_path, filename)\n",
    "            print(f\"\\nğŸ§ ì²˜ë¦¬ ì¤‘: {filename}\")\n",
    "\n",
    "            try:\n",
    "                # â–¶ ê³ ì • ì„¤ì •: í™”ì ìˆ˜ 1ëª…, ì´ë¦„ \"speaker\"\n",
    "                num_speakers = 1\n",
    "                speaker_names = [\"speaker\"]\n",
    "\n",
    "                # â–¶ ì˜¤ë””ì˜¤ ë¡œë“œ ë° (channel, time) ë³´ì •\n",
    "                waveform, sample_rate = torchaudio.load(wav_path)\n",
    "\n",
    "                if waveform.ndim == 1:\n",
    "                    waveform = waveform.unsqueeze(0)\n",
    "                elif waveform.ndim == 2 and waveform.shape[0] > waveform.shape[1]:\n",
    "                    waveform = waveform.T\n",
    "\n",
    "                # í™”ì ë¶„ë¦¬ ì‹¤í–‰\n",
    "                with ProgressHook() as hook:\n",
    "                    diarization = pipeline(\n",
    "                        {\"waveform\": waveform, \"sample_rate\": sample_rate},\n",
    "                        hook=hook,\n",
    "                        num_speakers=num_speakers\n",
    "                    )\n",
    "\n",
    "                # ê²°ê³¼ íŒŒì‹±\n",
    "                results = []\n",
    "                for turn, _, speaker_idx in diarization.itertracks(yield_label=True):\n",
    "                    speaker_label = speaker_names[0]\n",
    "                    results.append({\n",
    "                        \"start\": round(turn.start, 2),\n",
    "                        \"stop\": round(turn.end, 2),\n",
    "                        \"speaker\": speaker_label\n",
    "                    })\n",
    "\n",
    "                # ì—‘ì…€ ì €ì¥\n",
    "                out_path = os.path.splitext(wav_path)[0] + \"_diarization.xlsx\"\n",
    "                pd.DataFrame(results).to_excel(out_path, index=False)\n",
    "                print(f\"âœ… ì €ì¥ ì™„ë£Œ: {out_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ - ê±´ë„ˆëœ€: {filename}\")\n",
    "                print(f\"   â””â”€ ì´ìœ : {e}\")\n",
    "\n",
    "# â–¶ ë©”ì¸ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    process_directory(AUDIO_DIR)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
