{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from deepface import DeepFace\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def cosine_distance(v1, v2):\n",
    "    return cosine(v1, v2)\n",
    "\n",
    "def track_faces_mediapipe(video_path, output_dir=\"output_faces\", max_frames=300, threshold=0.5):\n",
    "    print(f\"[🚀 시작] '{video_path}' 에서 MediaPipe + ArcFace 얼굴 추적\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[❌ 오류] 비디오 열기 실패\")\n",
    "        return\n",
    "\n",
    "    mp_face = mp.solutions.face_detection\n",
    "    face_detection = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    person_db = {}\n",
    "    person_counter = 0\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened() and frame_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        print(f\"[📷 프레임 {frame_count}] 처리 중...\")\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(rgb)\n",
    "\n",
    "        if not results.detections:\n",
    "            print(\"  └─ 얼굴 없음\")\n",
    "            continue\n",
    "\n",
    "        for i, detection in enumerate(results.detections):\n",
    "            bbox = detection.location_data.relative_bounding_box\n",
    "            h, w, _ = frame.shape\n",
    "            x = int(bbox.xmin * w)\n",
    "            y = int(bbox.ymin * h)\n",
    "            w_box = int(bbox.width * w)\n",
    "            h_box = int(bbox.height * h)\n",
    "\n",
    "            x, y = max(x, 0), max(y, 0)\n",
    "            face_img = frame[y:y+h_box, x:x+w_box]\n",
    "\n",
    "            if w_box < 60 or h_box < 60:\n",
    "                print(\"    └─ 너무 작은 얼굴, 스킵\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                embedding = DeepFace.represent(face_img, model_name=\"ArcFace\", enforce_detection=False)[0]['embedding']\n",
    "            except Exception as e:\n",
    "                print(f\"    [!] 얼굴 아님 or 인식 실패: {e}\")\n",
    "                continue\n",
    "\n",
    "            matched_id = None\n",
    "            min_dist = 1.0\n",
    "\n",
    "            for pid, data in person_db.items():\n",
    "                avg_emb = np.mean(data['embeddings'], axis=0)\n",
    "                dist = cosine_distance(embedding, avg_emb)\n",
    "                if dist < threshold and dist < min_dist:\n",
    "                    matched_id = pid\n",
    "                    min_dist = dist\n",
    "\n",
    "            if matched_id:\n",
    "                person_id = matched_id\n",
    "                print(f\"    ✅ 기존 인물 인식됨: {person_id} (거리={min_dist:.4f})\")\n",
    "                person_db[person_id]['embeddings'].append(embedding)\n",
    "                person_db[person_id]['last_seen'] = frame_count\n",
    "            else:\n",
    "                person_counter += 1\n",
    "                person_id = f\"P{person_counter}\"\n",
    "                print(f\"    ➕ 새로운 인물 등록: {person_id}\")\n",
    "                person_db[person_id] = {\n",
    "                    'embeddings': [embedding],\n",
    "                    'last_seen': frame_count\n",
    "                }\n",
    "\n",
    "            # 저장\n",
    "            person_folder = os.path.join(output_dir, person_id)\n",
    "            os.makedirs(person_folder, exist_ok=True)\n",
    "            save_path = os.path.join(person_folder, f\"frame{frame_count}.jpg\")\n",
    "            cv2.imwrite(save_path, face_img)\n",
    "\n",
    "            # 시각화\n",
    "            cv2.rectangle(frame, (x, y), (x+w_box, y+h_box), (0,255,0), 2)\n",
    "            cv2.putText(frame, person_id, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"[🛑 사용자 종료]\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[✅ 완료] 얼굴 이미지 저장 완료\")\n",
    "\n",
    "# ✅ main\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"MediaPipe + ArcFace 얼굴 트래킹\")\n",
    "    parser.add_argument(\"video_path\", type=str, help=\"비디오 경로\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, default=\"output_faces\")\n",
    "    parser.add_argument(\"--max_frames\", type=int, default=300)\n",
    "    parser.add_argument(\"--threshold\", type=float, default=0.55)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    track_faces_mediapipe(\n",
    "        args.video_path,\n",
    "        args.output_dir,\n",
    "        args.max_frames,\n",
    "        args.threshold\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
