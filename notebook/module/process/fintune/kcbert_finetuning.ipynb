{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅ CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "\n",
    "# 1. 엑셀 데이터 불러오기\n",
    "df = pd.read_excel(\"test.xlsx\")\n",
    "df = df[['Sentence', 'Emotion']].copy()\n",
    "df.columns = ['sentence', 'label']\n",
    "\n",
    "# 2. 감정 라벨 숫자 인덱스로 매핑\n",
    "label2id = {'공포': 0, '놀람': 1, '분노': 2, '슬픔': 3, '중립': 4, '행복': 5, '혐오': 6}\n",
    "df = df[df['label'].isin(label2id.keys())].copy()\n",
    "df['label'] = df['label'].map(label2id)\n",
    "\n",
    "# 3. HuggingFace Dataset으로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 4. Tokenizer 로딩 및 토크나이징\n",
    "model_name = \"beomi/KcBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example['sentence'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "dataset = dataset.map(tokenize)\n",
    "\n",
    "# 5. 학습/검증 분할\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']\n",
    "\n",
    "# 6. 사전학습 모델 불러오기 (num_labels=7)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7)\n",
    "\n",
    "# 7. 학습 인자 설정 (D드라이브에 저장)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"D:/kcbert-emotion-checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"D:/kcbert-emotion-logs\",\n",
    "    logging_steps=100\n",
    ")\n",
    "\n",
    "# 8. Trainer 구성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# 9. 학습 시작\n",
    "trainer.train()\n",
    "\n",
    "# 10. 최종 모델 저장 (D드라이브)\n",
    "trainer.save_model(\"D:/kcbert-emotion-finetuned\")\n",
    "tokenizer.save_pretrained(\"D:/kcbert-emotion-finetuned\")\n",
    "\n",
    "# 예측\n",
    "predictions = trainer.predict(eval_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# 라벨 복원\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "target_names = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "# 성능 분석표 출력\n",
    "report = classification_report(labels, preds, target_names=target_names, digits=4)\n",
    "print(\"📊 감정별 성능 분석:\\n\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
