{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import Wav2Vec2FeatureExtractor, HubertForSequenceClassification\n",
    "\n",
    "class HuBERTEmotionByDiarization:\n",
    "    def __init__(self, model_name=\"superb/hubert-large-superb-er\", device=None):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "        self.model = HubertForSequenceClassification.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.label_map = {\n",
    "            0: \"neutral\",\n",
    "            1: \"calm\",\n",
    "            2: \"happy\",\n",
    "            3: \"sad\",\n",
    "            4: \"angry\",\n",
    "            5: \"fearful\",\n",
    "            6: \"disgust\",\n",
    "            7: \"surprised\"\n",
    "        }\n",
    "\n",
    "    def analyze_segment(self, waveform, sample_rate):\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "            waveform = resampler(waveform)\n",
    "            sample_rate = 16000\n",
    "\n",
    "        inputs = self.feature_extractor(waveform.squeeze().numpy(), sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0].cpu().numpy()  # üî• ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ\n",
    "\n",
    "        top_label = self.label_map[int(np.argmax(probs))]\n",
    "        return top_label, probs\n",
    "\n",
    "    def analyze_file(self, wav_path, diarization_path):\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        if waveform.ndim == 1:\n",
    "            waveform = waveform.unsqueeze(0)\n",
    "\n",
    "        diar_df = pd.read_excel(diarization_path)\n",
    "        results = []\n",
    "\n",
    "        for _, row in diar_df.iterrows():\n",
    "            start_sec = float(row[\"start\"])\n",
    "            stop_sec = float(row[\"stop\"])\n",
    "            start_sample = int(start_sec * sample_rate)\n",
    "            stop_sample = int(stop_sec * sample_rate)\n",
    "\n",
    "            segment = waveform[:, start_sample:stop_sample]\n",
    "            if segment.shape[1] < sample_rate:  # 1Ï¥à Ïù¥Ìïò skip\n",
    "                continue\n",
    "\n",
    "            emotion, probs = self.analyze_segment(segment, sample_rate)\n",
    "            results.append({\n",
    "                \"start_sec\": round(start_sec, 2),\n",
    "                \"stop_sec\": round(stop_sec, 2),\n",
    "                \"emotion\": emotion,\n",
    "                \"softmax\": {self.label_map[i]: round(float(p), 4) for i, p in enumerate(probs)}\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def analyze_directory(self, directory_path):\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if filename.endswith(\"_diarization.xlsx\"):\n",
    "                base = filename.replace(\"_diarization.xlsx\", \"\")\n",
    "                wav_path = os.path.join(directory_path, base + \".wav\")\n",
    "                diar_path = os.path.join(directory_path, filename)\n",
    "\n",
    "                if not os.path.exists(wav_path):\n",
    "                    print(f\"‚ùå WAV ÌååÏùº ÏóÜÏùå: {wav_path}\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"üîç Î∂ÑÏÑù Ï§ë: {base}\")\n",
    "                try:\n",
    "                    results = self.analyze_file(wav_path, diar_path)\n",
    "\n",
    "                    json_path = os.path.join(directory_path, base + \"_emotion.json\")\n",
    "                    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "                    print(f\"‚úÖ Ï†ÄÏû• ÏôÑÎ£å: {json_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù - Í±¥ÎÑàÎúÄ: {filename}\")\n",
    "                    print(f\"   ‚îî‚îÄ Ïù¥Ïú†: {e}\")\n",
    "\n",
    "# ‚úÖ Ïã§Ìñâ\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = HuBERTEmotionByDiarization()\n",
    "    analyzer.analyze_directory(\"D:/insta_downloads\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
