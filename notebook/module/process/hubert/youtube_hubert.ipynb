{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import Wav2Vec2FeatureExtractor, HubertForSequenceClassification\n",
    "\n",
    "class HuBERTEmotionByDiarization:\n",
    "    def __init__(self, model_name=\"superb/hubert-large-superb-er\", device=None):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "        self.model = HubertForSequenceClassification.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.label_map = {\n",
    "            0: \"neutral\",\n",
    "            1: \"calm\",\n",
    "            2: \"happy\",\n",
    "            3: \"sad\",\n",
    "            4: \"angry\",\n",
    "            5: \"fearful\",\n",
    "            6: \"disgust\",\n",
    "            7: \"surprised\"\n",
    "        }\n",
    "\n",
    "    def analyze_segment(self, waveform, sample_rate):\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "            waveform = resampler(waveform)\n",
    "            sample_rate = 16000\n",
    "\n",
    "        inputs = self.feature_extractor(waveform.squeeze().numpy(), sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0].cpu().numpy()\n",
    "\n",
    "        top_label = self.label_map[int(np.argmax(probs))]\n",
    "        return top_label, probs\n",
    "\n",
    "    def analyze_file(self, wav_path, diarization_path):\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        if waveform.ndim == 1:\n",
    "            waveform = waveform.unsqueeze(0)\n",
    "\n",
    "        # ✅ 전체 영상 길이 확인 (초)\n",
    "        total_duration = waveform.shape[1] / sample_rate\n",
    "        if total_duration >= 120:\n",
    "            print(f\"⏩ 2분 이상 영상 → 건너뜀 (길이: {round(total_duration, 2)}초)\")\n",
    "            return None\n",
    "\n",
    "        diar_df = pd.read_excel(diarization_path)\n",
    "        results = []\n",
    "\n",
    "        for _, row in diar_df.iterrows():\n",
    "            start_sec = float(row[\"start\"])\n",
    "            stop_sec = float(row[\"stop\"])\n",
    "            start_sample = int(start_sec * sample_rate)\n",
    "            stop_sample = int(stop_sec * sample_rate)\n",
    "\n",
    "            segment = waveform[:, start_sample:stop_sample]\n",
    "            if segment.shape[1] < sample_rate:  # 1초 이하 skip\n",
    "                continue\n",
    "\n",
    "            emotion, probs = self.analyze_segment(segment, sample_rate)\n",
    "            results.append({\n",
    "                \"start_sec\": round(start_sec, 2),\n",
    "                \"stop_sec\": round(stop_sec, 2),\n",
    "                \"emotion\": emotion,\n",
    "                \"softmax\": {self.label_map[i]: round(float(p), 4) for i, p in enumerate(probs)}\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def analyze_directory(self, directory_path):\n",
    "        diar_files = [f for f in os.listdir(directory_path) if f.endswith(\"_diarization.xlsx\")]\n",
    "        total = len(diar_files)\n",
    "\n",
    "        for idx, filename in enumerate(diar_files, start=1):\n",
    "            base = filename.replace(\"_diarization.xlsx\", \"\")\n",
    "            wav_path = os.path.join(directory_path, base + \".wav\")\n",
    "            diar_path = os.path.join(directory_path, filename)\n",
    "            json_path = os.path.join(directory_path, base + \"_emotion.json\")\n",
    "\n",
    "            if os.path.exists(json_path):\n",
    "                print(f\"⏩ [{idx}/{total}] 이미 분석됨: {json_path}\")\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(wav_path):\n",
    "                print(f\"❌ [{idx}/{total}] WAV 파일 없음: {wav_path}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"🔍 [{idx}/{total}] 분석 중: {base}\")\n",
    "            try:\n",
    "                results = self.analyze_file(wav_path, diar_path)\n",
    "\n",
    "                if results is None:\n",
    "                    continue  # 영상 길이 2분 이상 건너뜀\n",
    "\n",
    "                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "                print(f\"✅ 저장 완료: {json_path}\")\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" in str(e):\n",
    "                    print(\"🧹 CUDA 메모리 부족 → 캐시 정리 후 건너뜀\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                else:\n",
    "                    print(\"❌ RuntimeError 발생 - 건너뜀\")\n",
    "                print(f\"   └─ 이유: {e}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 기타 오류 발생 - 건너뜀: {filename}\")\n",
    "                print(f\"   └─ 이유: {e}\")\n",
    "\n",
    "# ✅ 실행\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = HuBERTEmotionByDiarization()\n",
    "    analyzer.analyze_directory(\"D:/youtube_downloads\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
