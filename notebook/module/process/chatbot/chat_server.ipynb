{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0453bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from collections import Counter\n",
    "from chat_execute import ask_function_call\n",
    "from chat_execute import analyze_comments_with_gpt\n",
    "from chat_execute import analyze_statistics_with_gpt\n",
    "from chat_execute import analyze_comparison_with_gpt\n",
    "from chat_execute import analyze_contents_with_gpt\n",
    "from rich import print as rprint\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# âœ… DB ì—°ê²°\n",
    "def connect_to_db():\n",
    "    return pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        password='172',\n",
    "        database='aaa',\n",
    "        charset='utf8mb4',\n",
    "        cursorclass=pymysql.cursors.DictCursor\n",
    "    )\n",
    "\n",
    "# âœ… ìœ íŠœë¸Œ ëŒ“ê¸€+ë©”íƒ€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "def get_youtube_comment_data(connection, influencer_name=None, date=None, video_url=None):\n",
    "    \"\"\"\n",
    "    ìœ íŠœë¸Œ ëŒ“ê¸€ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì¡°ê±´ì— ë”°ë¼ ì¡°íšŒ (topic_categories í¬í•¨)\n",
    "    :param connection: DB ì—°ê²° ê°ì²´\n",
    "    :param influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„\n",
    "    :param date: ì˜ìƒ ë‚ ì§œ\n",
    "    :param video_url: ì˜ìƒ URL\n",
    "    :return: ì¡°íšŒëœ ëŒ“ê¸€ ë° ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT \n",
    "            yc.video_url,\n",
    "            y.title,\n",
    "            yc.comment,\n",
    "            yc.emotion,\n",
    "            yc.topic,\n",
    "            y.topic_categories,  -- âœ… ì¶”ê°€ëœ ì»¬ëŸ¼\n",
    "            yc.cluster,\n",
    "            yc.score,\n",
    "            yc.fss as SCOPE_score,\n",
    "            y.view_count,\n",
    "            y.like_count,\n",
    "            y.comment_count,\n",
    "            y.subscriber_count,\n",
    "            y.date\n",
    "        FROM youtube_comment yc\n",
    "        JOIN youtube y ON yc.video_url = y.video_url\n",
    "    \"\"\"\n",
    "    conditions = []\n",
    "    params = []\n",
    "\n",
    "    if video_url:\n",
    "        conditions.append(\"y.video_url = %s\")\n",
    "        params.append(video_url)\n",
    "    else:\n",
    "        if influencer_name:\n",
    "            conditions.append(\"y.influencer_name = %s\")\n",
    "            params.append(influencer_name)\n",
    "        if date:\n",
    "            conditions.append(\"DATE(y.date) = %s\")\n",
    "            params.append(date)\n",
    "\n",
    "    if conditions:\n",
    "        query += \" WHERE \" + \" AND \".join(conditions)\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query, tuple(params))\n",
    "        return cursor.fetchall()\n",
    "\n",
    "def comments_sample(connection, influencer_name=None, date=None, limit=10,\n",
    "                    emotion=None, topic=None, cluster=None, video_url=None):\n",
    "    \"\"\"\n",
    "    ëŒ“ê¸€ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ê¸°ë³¸ 10ê°œ)\n",
    "    \"\"\"\n",
    "    data = get_youtube_comment_data(connection, influencer_name, date)\n",
    "    if not data:\n",
    "        return \"âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # âœ… ê°ì • ë§¤í•‘\n",
    "    emotion_map = {\n",
    "        \"positive\": [\"í–‰ë³µ\"],\n",
    "        \"negative\": [\"ë¶„ë…¸\", \"í˜ì˜¤\", \"ìŠ¬í””\"]\n",
    "    }\n",
    "\n",
    "    # âœ… í•„í„°ë§\n",
    "    filtered = []\n",
    "    for row in data:\n",
    "        if video_url and row[\"video_url\"] != video_url:\n",
    "            continue\n",
    "        if emotion:\n",
    "            if emotion in emotion_map:\n",
    "                if row[\"emotion\"] not in emotion_map[emotion]:\n",
    "                    continue\n",
    "            elif row[\"emotion\"] != emotion:\n",
    "                continue\n",
    "        if topic and row[\"topic\"] != topic:\n",
    "            continue\n",
    "        if cluster and row[\"cluster\"] != cluster:\n",
    "            continue\n",
    "        filtered.append(row)\n",
    "\n",
    "    if not filtered:\n",
    "        return \"âš ï¸ ì¡°ê±´ì— ë§ëŠ” ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # âœ… ë¬´ì‘ìœ„ ìƒ˜í”Œë§\n",
    "    sampled = random.sample(filtered, min(limit, len(filtered)))\n",
    "\n",
    "    # âœ… ê²°ê³¼ í¬ë§·\n",
    "    target_label = f\"{influencer_name or 'ì „ì²´'} - {date or 'ì „ì²´'}\"\n",
    "    if video_url:\n",
    "        target_label += f\" - ì˜ìƒ: {video_url}\"\n",
    "    if emotion in [\"positive\", \"negative\"]:\n",
    "        target_label += f\" - ê°ì •: {emotion}\"\n",
    "\n",
    "    lines = [f\"\\nğŸ“‹ [{target_label}] í•„í„°ë§ëœ ëŒ“ê¸€ ìƒ˜í”Œ {len(sampled)}ê°œ:\"]\n",
    "    for i, row in enumerate(sampled, 1):\n",
    "        lines.append(\n",
    "            f\"{i}. ({row['date']}) [{row['video_url']}] {row['comment']}\\n\"\n",
    "            f\"   â–¶ ê°ì •: {row['emotion']} / ì£¼ì œ: {row['topic']} / í´ëŸ¬ìŠ¤í„°: {row['cluster']} / \"\n",
    "            f\"ì ìˆ˜: {row['score']} / SCOPE_score: {row['SCOPE_score']}\"\n",
    "        )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# âœ… í‰ê·  ê³„ì‚°\n",
    "def calculate_average_stats(data):\n",
    "    keys = ['SCOPE_score', 'view_count', 'like_count', 'comment_count', 'subscriber_count']\n",
    "    avg_stats = {}\n",
    "    for key in keys:\n",
    "        values = [row[key] for row in data if row.get(key) is not None]\n",
    "        avg_stats[f\"avg_{key}\"] = sum(values) / len(values) if values else 0\n",
    "    return avg_stats\n",
    "\n",
    "# âœ… ë¶„í¬ ê³„ì‚°\n",
    "def calculate_distribution(data, key):\n",
    "    counter = Counter([row[key] for row in data if row.get(key)])\n",
    "    total = sum(counter.values())\n",
    "    return {k: round((v / total) * 100, 2) for k, v in counter.items()} if total > 0 else {}\n",
    "\n",
    "def format_stat_dict(title, stat_dict):\n",
    "    \"\"\"\n",
    "    í†µê³„ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…\n",
    "    :param title: ì¶œë ¥ ì œëª©\n",
    "    :param stat_dict: {í•­ëª©: ê°’} í˜•íƒœì˜ í‰ê·  í†µê³„ ë”•ì…”ë„ˆë¦¬\n",
    "    :return: í¬ë§·ëœ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    lines = [f\"\\n[{title}]\"]\n",
    "    for key, value in stat_dict.items():\n",
    "        lines.append(f\"{key}: {value:.2f}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def format_distribution(title, dist_dict):\n",
    "    \"\"\"\n",
    "    ë¶„í¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…\n",
    "    :param title: ì¶œë ¥ ì œëª©\n",
    "    :param dist_dict: {ì¹´í…Œê³ ë¦¬: í¼ì„¼íŠ¸} í˜•íƒœì˜ ë¶„í¬ ë”•ì…”ë„ˆë¦¬\n",
    "    :return: í¬ë§·ëœ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    lines = [f\"\\n[{title}]\"]\n",
    "    for key, pct in dist_dict.items():\n",
    "        lines.append(f\"- {key}: {pct}%\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# âœ… ë‚ ì§œ ì„ íƒ ìœ ë„\n",
    "def select_available_dates(connection, influencer_name):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ ìœ íš¨í•œ ë‚ ì§œ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ìµœê³ /ìµœì € SCOPE_score ë‚ ì§œ ê°•ì¡° í¬í•¨)\n",
    "    :param connection: DB ì—°ê²° ê°ì²´\n",
    "    :param influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„\n",
    "    :return: ë‚ ì§œ ëª©ë¡ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    # ìœ íš¨ ë‚ ì§œ ì¡°íšŒ\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT y.date \n",
    "        FROM youtube y \n",
    "        WHERE y.influencer_name = %s \n",
    "        ORDER BY y.date\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query, (influencer_name,))\n",
    "        rows = cursor.fetchall()\n",
    "        dates = [row['date'] for row in rows]\n",
    "\n",
    "    if not dates:\n",
    "        return f\"âš ï¸ [{influencer_name}]ì˜ ìœ íš¨í•œ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ìµœê³  ë° ìµœì € ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°\n",
    "    best_date = select_best_stats_date(connection, influencer_name)\n",
    "    worst_date = select_worst_stats_date(connection, influencer_name)\n",
    "\n",
    "    result = [f\"ğŸ“… [{influencer_name}]ì˜ ìœ íš¨í•œ ë‚ ì§œ ëª©ë¡:\"]\n",
    "    for i, date in enumerate(dates):\n",
    "        label = \"\"\n",
    "        if date == best_date:\n",
    "            label += \"ğŸŒŸ ìµœê³  ì„±ê³¼ì¼\"\n",
    "        if date == worst_date:\n",
    "            if label: label += \" / \"\n",
    "            label += \"ğŸ“‰ ìµœì € ì„±ê³¼ì¼\"\n",
    "        result.append(f\"{i + 1}. {date}\" + (f\"  â† {label}\" if label else \"\"))\n",
    "    \n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "def select_available_influencers(connection):\n",
    "    \"\"\"\n",
    "    ìœ íš¨í•œ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    :param connection: DB ì—°ê²° ê°ì²´\n",
    "    :return: ì¸í”Œë£¨ì–¸ì„œ ëª©ë¡ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT influencer_name \n",
    "        FROM youtube \n",
    "        ORDER BY influencer_name\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        names = [row['influencer_name'] for row in rows]\n",
    "\n",
    "    if not names:\n",
    "        return \"âš ï¸ ë“±ë¡ëœ ì¸í”Œë£¨ì–¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    result = [\"ğŸ§‘â€ğŸ’» ìœ íš¨í•œ ì¸í”Œë£¨ì–¸ì„œ ëª©ë¡:\"]\n",
    "    for i, name in enumerate(names):\n",
    "        result.append(f\"{i + 1}. {name}\")\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "def select_available_video_urls(connection, influencer_name):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ ìœ íš¨í•œ ì˜ìƒ ì œëª© ë° YouTube ID ëª©ë¡ì„ ë‚ ì§œë³„ë¡œ ì •ë¦¬í•´ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    :param connection: DB ì—°ê²° ê°ì²´\n",
    "    :param influencer_name: ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„\n",
    "    :return: ì˜ìƒ ì œëª© ëª©ë¡ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT date, title, video_url\n",
    "        FROM youtube\n",
    "        WHERE influencer_name = %s\n",
    "        ORDER BY date\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query, (influencer_name,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "    if not rows:\n",
    "        return f\"âš ï¸ [{influencer_name}]ì˜ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    result = [f\"ğŸ¬ [{influencer_name}]ì˜ ì˜ìƒ ëª©ë¡ (ì œëª© + YouTube ID):\"]\n",
    "    for i, row in enumerate(rows):\n",
    "        date = row['date']\n",
    "        title = row['title']\n",
    "        url = row['video_url']\n",
    "        video_id = url.split(\"v=\")[-1].split(\"&\")[0] if \"v=\" in url else \"â“ID ì—†ìŒ\"\n",
    "        result.append(f\"{i + 1}. ({date}) ã€{title}ã€ (ğŸï¸ ID: {video_id})\")\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "# âœ… ìµœê³  SCOPE_score ë‚ ì§œ êµ¬í•˜ê¸°\n",
    "def select_best_stats_date(connection, influencer_name):\n",
    "    query = \"\"\"\n",
    "        SELECT y.date\n",
    "        FROM youtube_comment yc\n",
    "        JOIN youtube y ON yc.video_url = y.video_url\n",
    "        WHERE y.influencer_name = %s\n",
    "        GROUP BY y.date\n",
    "        ORDER BY AVG(fss) DESC\n",
    "        LIMIT 1\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query, (influencer_name,))\n",
    "        row = cursor.fetchone()\n",
    "        return row['date'] if row else None\n",
    "\n",
    "# âœ… ìµœì € SCOPE_score ë‚ ì§œ êµ¬í•˜ê¸°\n",
    "def select_worst_stats_date(connection, influencer_name):\n",
    "    query = \"\"\"\n",
    "        SELECT y.date\n",
    "        FROM youtube_comment yc\n",
    "        JOIN youtube y ON yc.video_url = y.video_url\n",
    "        WHERE y.influencer_name = %s\n",
    "        GROUP BY y.date\n",
    "        ORDER BY AVG(fss) ASC\n",
    "        LIMIT 1\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query, (influencer_name,))\n",
    "        row = cursor.fetchone()\n",
    "        return row['date'] if row else None\n",
    "\n",
    "def compare_two_stats(original_stats, compare_stats):\n",
    "    \"\"\"\n",
    "    ë‘ ê°œì˜ í†µê³„ dictë¥¼ ë¹„êµí•˜ì—¬ í•­ëª©ë³„ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜ (ì ˆëŒ“ê°’ + í¼ì„¼íŠ¸ ì°¨ì´)\n",
    "    \"\"\"\n",
    "    result = [f\"\\nğŸ“Š í•­ëª©ë³„ ì°¨ì´ (ê¸°ì¤€ - ë¹„êµëŒ€ìƒ)\"]\n",
    "    for key in original_stats:\n",
    "        if key.startswith(\"avg_\") and key in compare_stats:\n",
    "            orig = original_stats[key]\n",
    "            comp = compare_stats[key]\n",
    "            diff = orig - comp\n",
    "\n",
    "            # í¼ì„¼íŠ¸ ì°¨ì´ ê³„ì‚° (compê°€ 0ì´ë©´ 'N/A')\n",
    "            if comp == 0:\n",
    "                pct = \"N/A\"\n",
    "            else:\n",
    "                pct = f\"{(diff / comp) * 100:+.2f}%\"\n",
    "\n",
    "            result.append(f\"{key}: {orig:.2f} - {comp:.2f} = {diff:+.2f} ({pct})\")\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "def compare_distributions(dist1, dist2):\n",
    "    \"\"\"\n",
    "    ë‘ ë¶„í¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¹„êµí•˜ì—¬ ê³µí†µëœ ë¼ë²¨ì— ëŒ€í•´ í¼ì„¼íŠ¸ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    lines = [f\"\\nğŸ“Š ê³µí†µ ì¹´í…Œê³ ë¦¬ë³„ í¼ì„¼íŠ¸ ì°¨ì´ (ê¸°ì¤€ - ë¹„êµëŒ€ìƒ)\"]\n",
    "\n",
    "    common_keys = set(dist1.keys()).intersection(dist2.keys())\n",
    "    if not common_keys:\n",
    "        lines.append(\"âš ï¸ ê³µí†µëœ ë¼ë²¨ì´ ì—†ì–´ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    for key in sorted(common_keys):\n",
    "        try:\n",
    "            val1 = dist1[key]\n",
    "            val2 = dist2[key]\n",
    "            diff = val1 - val2\n",
    "            lines.append(f\"{key}: {val1:.2f}% - {val2:.2f}% = {diff:+.2f}pp\")\n",
    "        except Exception as e:\n",
    "            lines.append(f\"{key}: ë¹„êµ ì‹¤íŒ¨ ({e})\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "#ì „ì²´ ì¸í”Œë£¨ì–¸ì„œ í‰ê·  í†µê³„ ë³´ì—¬ì¤˜\n",
    "def get_global_statistics(connection):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ì¸í”Œë£¨ì–¸ì„œì˜ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    all_data = get_youtube_comment_data(connection)\n",
    "    lines = [\n",
    "        format_stat_dict(\"ì „ì²´ ì¸í”Œë£¨ì–¸ì„œ í‰ê·  í†µê³„\", calculate_average_stats(all_data)),\n",
    "        format_distribution(\"ì „ì²´ ê°ì • ë¶„í¬\", calculate_distribution(all_data, \"emotion\")),\n",
    "        format_distribution(\"ì „ì²´ ì£¼ì œ ë¶„í¬\", calculate_distribution(all_data, \"topic\")),\n",
    "        format_distribution(\"ì „ì²´ í´ëŸ¬ìŠ¤í„° ë¶„í¬\", calculate_distribution(all_data, \"cluster\")),\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "#íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œ í‰ê·  í†µê³„ ë³´ì—¬ì¤˜\n",
    "def get_influencer_statistics(connection, influencer_name):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    inf_data = get_youtube_comment_data(connection, influencer_name)\n",
    "    lines = [\n",
    "        format_stat_dict(f\"{influencer_name} í‰ê·  í†µê³„\", calculate_average_stats(inf_data)),\n",
    "        format_distribution(f\"{influencer_name} ê°ì • ë¶„í¬\", calculate_distribution(inf_data, \"emotion\")),\n",
    "        format_distribution(f\"{influencer_name} ì£¼ì œ ë¶„í¬\", calculate_distribution(inf_data, \"topic\")),\n",
    "        format_distribution(f\"{influencer_name} í´ëŸ¬ìŠ¤í„° ë¶„í¬\", calculate_distribution(inf_data, \"cluster\")),\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "#íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ íŠ¹ì • ë‚ ì§œ í†µê³„ ë³´ì—¬ì¤˜\n",
    "def get_statistics_by_date(connection, influencer_name, selected_date):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    date_data = get_youtube_comment_data(connection, influencer_name, selected_date)\n",
    "    lines = [\n",
    "        format_stat_dict(f\"{influencer_name}ì˜ {selected_date} í‰ê·  í†µê³„\", calculate_average_stats(date_data)),\n",
    "        format_distribution(f\"{influencer_name}ì˜ {selected_date} ê°ì • ë¶„í¬\", calculate_distribution(date_data, \"emotion\")),\n",
    "        format_distribution(f\"{influencer_name}ì˜ {selected_date} ì£¼ì œ ë¶„í¬\", calculate_distribution(date_data, \"topic\")),\n",
    "        format_distribution(f\"{influencer_name}ì˜ {selected_date} í´ëŸ¬ìŠ¤í„° ë¶„í¬\", calculate_distribution(date_data, \"cluster\")),\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def get_statistics_by_video_url(connection, video_url):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • video_url(í•´ì‹œ or ì „ì²´ URL)ì— ëŒ€í•œ í‰ê·  í†µê³„ ë° ê°ì •/ì£¼ì œ/í´ëŸ¬ìŠ¤í„° ë¶„í¬ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    # URL í•´ì‹œê°’ë§Œ ë“¤ì–´ì™”ë‹¤ë©´ ì „ì²´ URLë¡œ ë³€í™˜\n",
    "    if not video_url.startswith(\"http\"):\n",
    "        video_url = f\"https://www.youtube.com/watch?v={video_url}\"\n",
    "\n",
    "    video_data = get_youtube_comment_data(connection, video_url=video_url)\n",
    "\n",
    "    if not video_data:\n",
    "        return f\"âš ï¸ í•´ë‹¹ ì˜ìƒ({video_url})ì— ëŒ€í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    title = video_data[0]['title']\n",
    "    date = video_data[0]['date']\n",
    "\n",
    "    lines = [\n",
    "        format_stat_dict(f\"ğŸ¥ ã€{title}ã€ ({date}) í‰ê·  í†µê³„\", calculate_average_stats(video_data)),\n",
    "        format_distribution(f\"ğŸ­ ã€{title}ã€ ê°ì • ë¶„í¬\", calculate_distribution(video_data, \"emotion\")),\n",
    "        format_distribution(f\"ğŸ§  ã€{title}ã€ ì£¼ì œ ë¶„í¬\", calculate_distribution(video_data, \"topic\")),\n",
    "        format_distribution(f\"ğŸ‘¥ ã€{title}ã€ í´ëŸ¬ìŠ¤í„° ë¶„í¬\", calculate_distribution(video_data, \"cluster\")),\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def compare_two_influencers_dates(connection, influencer1,influencer2=None, date1=None, date2=None):\n",
    "    \"\"\"\n",
    "    ë‘ ì¸í”Œë£¨ì–¸ì„œì˜ íŠ¹ì • ë‚ ì§œ ë˜ëŠ” ì „ì²´ ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ í‰ê·  í†µê³„ ë° ë¶„í¬ ì°¨ì´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    :param connection: DB ì—°ê²° ê°ì²´\n",
    "    :param influencer1: ì²« ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„\n",
    "    :param date1: ì²« ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ë‚ ì§œ (Noneì´ë©´ ì „ì²´)\n",
    "    :param influencer2: ë‘ ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„ (Noneì´ë©´ influencer1ê³¼ ë™ì¼í•˜ê²Œ ë¹„êµ)\n",
    "    :param date2: ë‘ ë²ˆì§¸ ì¸í”Œë£¨ì–¸ì„œ ë‚ ì§œ (Noneì´ë©´ ì „ì²´)\n",
    "    :return: ë¹„êµ ê²°ê³¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    if not influencer2:\n",
    "        influencer2 = influencer1  # ê°™ì€ ì‚¬ëŒ ë¹„êµ\n",
    "\n",
    "    result_lines = []\n",
    "\n",
    "    # ğŸ”¹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "    data1 = get_youtube_comment_data(connection, influencer1, date1)\n",
    "    data2 = get_youtube_comment_data(connection, influencer2, date2)\n",
    "\n",
    "    # ğŸ”¹ íƒ€ì´í‹€ ì„¤ì •\n",
    "    title = f\"{influencer1}({date1 or 'ì „ì²´'}) vs {influencer2}({date2 or 'ì „ì²´'}) í‰ê·  í†µê³„ ë¹„êµ\"\n",
    "\n",
    "    # ğŸ“Š í‰ê·  í†µê³„ ë¹„êµ\n",
    "    avg_stats_1 = calculate_average_stats(data1)\n",
    "    avg_stats_2 = calculate_average_stats(data2)\n",
    "    result_lines.append(compare_two_stats(avg_stats_1, avg_stats_2))\n",
    "\n",
    "    # ğŸ“Š ë¶„í¬ ë¹„êµ (ê°ì •, ì£¼ì œ, í´ëŸ¬ìŠ¤í„°)\n",
    "    for category in [\"emotion\", \"topic\", \"cluster\"]:\n",
    "        dist_1 = calculate_distribution(data1, category)\n",
    "        dist_2 = calculate_distribution(data2, category)\n",
    "        result_lines.append(\n",
    "            compare_distributions(\n",
    "                dist_1, dist_2\n",
    "                )\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "def analyze_overall_fss_by_category(connection, influencer_name, top_n=3, min_count=5):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ì¸í”Œë£¨ì–¸ì„œì˜ ì „ì²´ ì½˜í…ì¸ ì— ëŒ€í•´ topic_categoriesë³„ í‰ê·  FSS ë¶„ì„\n",
    "    (Wikipedia URLì€ í•­ëª© ì´ë¦„ë§Œ ì¶”ì¶œí•´ í‘œì‹œ)\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "\n",
    "    video_data = get_youtube_comment_data(connection, influencer_name=influencer_name)\n",
    "    \n",
    "    if not video_data:\n",
    "        return f\"âš ï¸ [{influencer_name}]ì— ëŒ€í•œ ëŒ“ê¸€ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    category_scores = defaultdict(list)\n",
    "\n",
    "    for row in video_data:\n",
    "        raw = row.get('topic_categories') or \"ë¯¸ë¶„ë¥˜\"\n",
    "        score = row.get('SCOPE_score')\n",
    "        if score is not None:\n",
    "            category_scores[raw].append(score)\n",
    "\n",
    "    filtered = {\n",
    "        cat: scores for cat, scores in category_scores.items()\n",
    "        if len(scores) >= min_count\n",
    "    }\n",
    "\n",
    "    if not filtered:\n",
    "        return f\"âš ï¸ ë¶„ì„ ê°€ëŠ¥í•œ ì£¼ì œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. (ëŒ“ê¸€ ìˆ˜ ë¶€ì¡±)\"\n",
    "\n",
    "    category_avg = {\n",
    "        cat: sum(scores) / len(scores)\n",
    "        for cat, scores in filtered.items()\n",
    "    }\n",
    "\n",
    "    sorted_avg = sorted(category_avg.items(), key=lambda x: x[1], reverse=True)\n",
    "    top = sorted_avg[:top_n]\n",
    "    bottom = sorted_avg[-top_n:]\n",
    "\n",
    "    def simplify_category(cat):\n",
    "        if cat == \"ë¯¸ë¶„ë¥˜\":\n",
    "            return cat\n",
    "        # ì—¬ëŸ¬ ê°œì¼ ê²½ìš° ë¶„ë¦¬ í›„ ê°ê° ì²˜ë¦¬\n",
    "        parts = [part.strip() for part in cat.split(',')]\n",
    "        simplified = []\n",
    "        for p in parts:\n",
    "            if \"en.wikipedia.org/wiki/\" in p:\n",
    "                simplified.append(p.split(\"en.wikipedia.org/wiki/\")[-1])\n",
    "            else:\n",
    "                simplified.append(p)\n",
    "        return \", \".join(simplified)\n",
    "\n",
    "    lines = [f\"\\nğŸ“ˆ [{influencer_name}]ë‹˜ì˜ ì½˜í…ì¸  ë°©í–¥ì„± ì œì•ˆ (SCOPE_score ê¸°ë°˜):\"]\n",
    "\n",
    "    lines.append(\"\\nâœ… ì•ìœ¼ë¡œ ë” í™œìš©í•´ë³¼ë§Œí•œ ì£¼ì œ ì¹´í…Œê³ ë¦¬:\")\n",
    "    for cat, avg in top:\n",
    "        lines.append(f\"  - {simplify_category(cat)}: í‰ê·  SCOPE_score {avg:.2f}\")\n",
    "\n",
    "    lines.append(\"\\nâš ï¸ ë°˜ì‘ì´ ë‚®ì•˜ë˜ ì£¼ì œ ì¹´í…Œê³ ë¦¬:\")\n",
    "    for cat, avg in bottom:\n",
    "        lines.append(f\"  - {simplify_category(cat)}: í‰ê·  SCOPE_score {avg:.2f}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def ask_for_additional_analysis():\n",
    "    user_input = input(\"\\nğŸ§  ì¶”ê°€ GPT ë¶„ì„ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \").strip().lower()\n",
    "    return user_input == \"y\"\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route(\"/chat\", methods=[\"POST\"])\n",
    "def chat_with_scope():\n",
    "    user_query = request.json.get(\"query\")\n",
    "    if not user_query:\n",
    "        return jsonify({\"error\": \"No query provided.\"}), 400\n",
    "\n",
    "    try:\n",
    "        rprint(f\"\\nğŸ‘¤ ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\")\n",
    "\n",
    "        call_string = ask_function_call(user_query)\n",
    "        rprint(f\"ğŸ“Œ í˜¸ì¶œí•  í•¨ìˆ˜: [cyan]{call_string}[/cyan]\")\n",
    "\n",
    "        true_call_string = call_string.strip('\"')\n",
    "        result_text = \"\"\n",
    "        gpt_summary = \"\"\n",
    "\n",
    "        # í•¨ìˆ˜ ì‹¤í–‰\n",
    "        if true_call_string.startswith((\"select_\", \"analyze_\", \"get_\", \"compare_\", \"comments_\")):\n",
    "            result_text = eval(true_call_string)\n",
    "            rprint(f\"ğŸ“Š ê²°ê³¼:\\n{result_text}\")\n",
    "\n",
    "            # ì¶”ê°€ GPT ë¶„ì„ ìš”ì²­ì€ ìë™ ì•„ë‹˜ (ë³„ë„ ìš”ì²­)\n",
    "            if request.json.get(\"gpt\") == True:\n",
    "                rprint(\"\\n[bold magenta]GPT ë¶„ì„ ì¤‘...[/bold magenta]\")\n",
    "                if true_call_string.startswith(\"comments_\"):\n",
    "                    gpt_summary = analyze_comments_with_gpt(result_text)\n",
    "                elif true_call_string.startswith(\"compare_\"):\n",
    "                    gpt_summary = analyze_comparison_with_gpt(user_query + result_text)\n",
    "                elif true_call_string.startswith(\"get_\"):\n",
    "                    gpt_summary = analyze_statistics_with_gpt(result_text)\n",
    "                elif true_call_string.startswith(\"analyze_\"):\n",
    "                    gpt_summary = analyze_contents_with_gpt(result_text)\n",
    "\n",
    "        else:\n",
    "            result_text = \"âš ï¸ í˜¸ì¶œ ê°€ëŠ¥í•œ í•¨ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤.\"\n",
    "\n",
    "        return jsonify({\n",
    "            \"function_call\": true_call_string,\n",
    "            \"result\": result_text,\n",
    "            \"gpt_summary\": gpt_summary\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        rprint(f\"[bold red]âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}[/bold red]\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    connection = connect_to_db()\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
