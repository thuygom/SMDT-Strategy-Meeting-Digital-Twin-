{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecdde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import math\n",
    "\n",
    "# OpenAI ì´ˆê¸°í™”\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "dir_path = 'C:/Users/bandl/OneDrive/ë°”íƒ• í™”ë©´/youtube_data/instagram_data/influencer'\n",
    "\n",
    "# ğŸ” GPT ë°°ì¹˜ ë¶„ë¥˜ í•¨ìˆ˜ (10ê°œì”© ë¬¶ìŒ)\n",
    "def classify_batch(comments, sentiments):\n",
    "    comments_block = \"\\n\".join(\n",
    "        f\"{i+1}. \\\"{comment}\\\" [Sentiment: {sentiment}]\"\n",
    "        for i, (comment, sentiment) in enumerate(zip(comments, sentiments))\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a comment classifier.\n",
    "\n",
    "For each of the following comments, return:\n",
    "- Topic: one of the following categories:\n",
    "  0 ì‚¬ê±´ / ë…¼ë€\n",
    "  1 ì½˜í…ì¸  í‰ê°€\n",
    "  2 ìœ íŠœë²„ ê°œì¸\n",
    "  3 ì œí’ˆ / ì•„ì´í…œ ë¦¬ë·°\n",
    "  4 ì‚¬íšŒ / ì‹œì‚¬ ì´ìŠˆ\n",
    "  5 ê³µê° / ê°ì • ê³µìœ \n",
    "  6 ì •ë³´ / ê¿€íŒ\n",
    "  7 ìœ ë¨¸ / ë“œë¦½\n",
    "  8 ì§ˆë¬¸ / í”¼ë“œë°±\n",
    "  9 ê¸°íƒ€ / ë¯¸ë¶„ë¥˜\n",
    "\n",
    "- Cluster: one of these:\n",
    "  Aggressive, Supportive, Neutral Informative, Sarcastic/Playful, Analytical, Spam/Promotional, Empathetic\n",
    "\n",
    "Respond in this format only:\n",
    "[Number]. Topic: [label], Cluster: [label]\n",
    "\n",
    "Here are the comments:\n",
    "{comments_block}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        lines = response.choices[0].message.content.strip().splitlines()\n",
    "        topics = []\n",
    "        clusters = []\n",
    "        for line in lines:\n",
    "            if \".\" in line and \"Topic:\" in line and \"Cluster:\" in line:\n",
    "                parts = line.split(\"Topic:\")[1].split(\", Cluster:\")\n",
    "                topic = parts[0].strip()\n",
    "                cluster = parts[1].strip()\n",
    "                topics.append(topic)\n",
    "                clusters.append(cluster)\n",
    "        return topics, clusters\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ GPT ì˜¤ë¥˜: {e}\")\n",
    "        return [\"ì˜¤ë¥˜\"] * len(comments), [\"ì˜¤ë¥˜\"] * len(comments)\n",
    "\n",
    "# ğŸ” ëª¨ë“  ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        print(f\"\\nğŸ“‚ ì²˜ë¦¬ ì¤‘: {filename}\")\n",
    "\n",
    "        try:\n",
    "            df = pd.read_excel(file_path)\n",
    "\n",
    "            # í•„ìˆ˜ ì—´ í™•ì¸\n",
    "            if 'ëŒ“ê¸€' not in df.columns or 'ê°ì •' not in df.columns:\n",
    "                print(f\"âš ï¸ 'ëŒ“ê¸€' ë˜ëŠ” 'ê°ì •' ì—´ì´ ì—†ìŒ: {filename}\")\n",
    "                continue\n",
    "\n",
    "            # âœ… ì´ë¯¸ 'ì£¼ì œ'ì™€ 'êµ°ì§‘' ì—´ì´ ëª¨ë‘ ì±„ì›Œì ¸ ìˆìœ¼ë©´ ìƒëµ\n",
    "            if 'ì£¼ì œ' in df.columns and 'êµ°ì§‘' in df.columns:\n",
    "                if df['ì£¼ì œ'].notna().all() and df['êµ°ì§‘'].notna().all():\n",
    "                    print(f\"â© ì´ë¯¸ ë¶„ë¥˜ë¨: {filename}\")\n",
    "                    continue\n",
    "\n",
    "            topic_result = []\n",
    "            cluster_result = []\n",
    "\n",
    "            batch_size = 10\n",
    "            total = math.ceil(len(df) / batch_size)\n",
    "\n",
    "            for i in tqdm(range(0, len(df), batch_size), desc=\"ğŸ” GPT ë¶„ë¥˜ ì¤‘\"):\n",
    "                comment_batch = df['ëŒ“ê¸€'].iloc[i:i+batch_size].tolist()\n",
    "                sentiment_batch = df['ê°ì •'].iloc[i:i+batch_size].tolist()\n",
    "                topics, clusters = classify_batch(comment_batch, sentiment_batch)\n",
    "\n",
    "                # âœ… index ë§¤ì¹­ ì˜¤ë¥˜ ë°©ì§€: ê²°ê³¼ ê°œìˆ˜ ê²€ì¦\n",
    "                if len(topics) != len(comment_batch) or len(clusters) != len(comment_batch):\n",
    "                    print(f\"âš ï¸ ê²°ê³¼ ëˆ„ë½ â†’ ì±„ì›Œë„£ìŒ (i={i}): topics={len(topics)}, clusters={len(clusters)}, expected={len(comment_batch)}\")\n",
    "                    topics = [\"ì˜¤ë¥˜\"] * len(comment_batch)\n",
    "                    clusters = [\"ì˜¤ë¥˜\"] * len(comment_batch)\n",
    "\n",
    "                topic_result.extend(topics)\n",
    "                cluster_result.extend(clusters)\n",
    "\n",
    "                time.sleep(0.1)\n",
    "\n",
    "            # ê¸°ì¡´ ì—´ ì œê±°\n",
    "            if 'ì£¼ì œ' in df.columns:\n",
    "                df.drop(columns=['ì£¼ì œ'], inplace=True)\n",
    "            if 'êµ°ì§‘' in df.columns:\n",
    "                df.drop(columns=['êµ°ì§‘'], inplace=True)\n",
    "\n",
    "            # âœ… index ê°œìˆ˜ ì¼ì¹˜ ì—¬ë¶€ ìµœì¢… ì²´í¬\n",
    "            if len(topic_result) != len(df) or len(cluster_result) != len(df):\n",
    "                raise ValueError(f\"âŒ ê²°ê³¼ ê¸¸ì´ ë¶ˆì¼ì¹˜: topic={len(topic_result)}, cluster={len(cluster_result)}, df={len(df)}\")\n",
    "\n",
    "            df.insert(8, 'ì£¼ì œ', topic_result)\n",
    "            df.insert(9, 'êµ°ì§‘', cluster_result)\n",
    "\n",
    "            df.to_excel(file_path, index=False)\n",
    "            print(f\"âœ… ì €ì¥ ì™„ë£Œ: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ ({filename}): {e}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
